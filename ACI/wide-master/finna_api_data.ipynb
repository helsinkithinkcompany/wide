{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.775749585371992"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_search_queries = len(results)\n",
    "#size_of_query = -np.log(num_search_queries/total_entries_in_yr) # perform log transformation to work with larger numbers\n",
    "#size_of_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future work: use publishDate instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from finna_client import FinnaClient as fc\n",
    "from finna_client import FinnaSearchType as fst \n",
    "\n",
    "#################################\n",
    "\n",
    "#### USER INPUT / PARAMETERS ####\n",
    "search_query = \"EEG\"\n",
    "year = 2018              # SLIDER\n",
    "#################################\n",
    "\n",
    "fc = fc() \n",
    "\n",
    "# input: int year\n",
    "# output: int total entries by year\n",
    "def get_total_entries_by_yr(year):\n",
    "    return fc.search(lookfor=\"\",\n",
    "           search_type=fst.Subject,\n",
    "           fields=[\"year\"],\n",
    "           filters=[(\"main_date_str:\"+str(year))],\n",
    "           page=1,\n",
    "           limit=100)['resultCount']\n",
    "\n",
    "\n",
    "def get_response(pg, search_query):\n",
    "    return fc.search(lookfor=search_query,\n",
    "           search_type=fst.Subject,\n",
    "           fields=[\"title\", \"buildings\", \"subjects\"],\n",
    "           filters=[(\"main_date_str:\"+str(year))],\n",
    "           facets=[\"author\"],\n",
    "           page=pg,\n",
    "           limit=100)\n",
    "\n",
    "\n",
    "def get_entries(year, search_query):\n",
    "    total_entries_in_yr = get_total_entries_by_yr(year)\n",
    "\n",
    "    total_pages = 0\n",
    "    results = []\n",
    "    while True:\n",
    "        try:\n",
    "            response = get_response(total_pages, search_query)\n",
    "            results += response['records']\n",
    "            total_pages += 1\n",
    "\n",
    "            # stopping condition\n",
    "            if len(results) >= response['resultCount']:\n",
    "                break     \n",
    "                \n",
    "        except:\n",
    "            print(\"num collected entries: \", len(results))\n",
    "            print(\"num expected entries: \", response['resultCount'])\n",
    "            break\n",
    "    \n",
    "    num_search_queries = len(results)\n",
    "            \n",
    "    data = json.dumps(results)\n",
    "    df = pd.read_json(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_num_entry_by_org_size_scores(df, year):\n",
    "    num_search_queries = len(df)\n",
    "    \n",
    "    buildings = []\n",
    "\n",
    "    for i in range(num_search_queries):\n",
    "        buildings.append(df['buildings'][i][0]['translated'])\n",
    "\n",
    "    unique_org = Counter(buildings).keys() # equals to list(set(words))\n",
    "    num_entries_by_org = Counter(buildings).values() # counts the elements' frequency\n",
    "    by_org_size_scores = [np.sqrt(x/num_search_queries)*100 for x in num_entries_by_org]\n",
    "\n",
    "    num_entry_by_org_size_scores = list(zip(unique_org, by_org_size_scores))\n",
    "\n",
    "    institutions = []\n",
    "    size_values = []\n",
    "    for i in range(len(num_entry_by_org_size_scores)):\n",
    "        institutions.append(num_entry_by_org_size_scores[i][0])\n",
    "        size_values.append(num_entry_by_org_size_scores[i][1])\n",
    "\n",
    "    json_data = {\n",
    "        \"institutions\" : institutions,\n",
    "        \"size_values\" : size_values\n",
    "    }\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "\n",
    "# co-occurrence matrix, work from 2000 - 2018\n",
    "def get_cooccurrence_matrix(df):\n",
    "    #df['subjects'].apply(pd.Series).stack().unique()\n",
    "    #list(set([a for b in df.val.tolist() for a in b]))\n",
    "\n",
    "    # toy example\n",
    "    # sample = [[[1]],[[1,1]],[[1,1,1]]]\n",
    "    # pd.DataFrame(sample).values.argmax()\n",
    "\n",
    "    #num_search_queries = len(df)\n",
    "    #idx_of_max_num_subjects = df['subjects'].values.argmax()\n",
    "    #len(df.loc[idx_of_max_num_subjects]['subjects'])\n",
    "\n",
    "    # to lowercase and strip ( . )\n",
    "    # toy example\n",
    "    # sample = [[[[\"Aa\"]]],[[[\"Bb\"]]],[[[\"Cc.\"],[\"Dd\"]]]]\n",
    "    # pd.DataFrame(sample).loc[2][0][0][0].lower().replace('.','')\n",
    "\n",
    "    subjects = [a[0].lower().replace('.','') for b in df['subjects'].tolist() for a in b]\n",
    "\n",
    "    unique_subject_list = list(set(subjects))\n",
    "    len(unique_subject_list)\n",
    "\n",
    "    subject_frequency = Counter(subjects).most_common() # counts the elements' frequency\n",
    "\n",
    "    # more data cleaning -> plural cases\n",
    "\n",
    "    # get the top commonly seen keywords occurring with the search query\n",
    "    TOP_VALUES = 10\n",
    "\n",
    "    key_subjects = []\n",
    "    for i in range(TOP_VALUES):\n",
    "        key_subjects.append(subject_frequency[i][0])\n",
    "\n",
    "    mat = np.zeros((len(df['subjects']), len(key_subjects)))\n",
    "\n",
    "\n",
    "    #subjects_by_publication\n",
    "    for x in range(len(df['subjects'])):\n",
    "        for y in range(len(key_subjects)):\n",
    "            for idx in range(len(df['subjects'][x])):\n",
    "                if df['subjects'][x][idx][0].lower().replace('.','') == key_subjects[y]:\n",
    "                    mat[x][y] += 1\n",
    "\n",
    "    co_mat = pd.DataFrame(mat.T.dot(mat), columns=key_subjects).astype(int)\n",
    "    np.fill_diagonal(co_mat.values, 0) # fill diagonal with 0\n",
    "\n",
    "    comat_json = {\n",
    "        \"data\": co_mat.values.tolist(),\n",
    "        \"label\": key_subjects\n",
    "    }\n",
    "    \n",
    "    return comat_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### USER INPUT / PARAMETERS ####\n",
    "search_query = \"EEG\"\n",
    "year = 2018             # SLIDER\n",
    "#################################\n",
    "\n",
    "df = get_entries(year, search_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80.0, 56.568542494923804, 20.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_entry_by_org_size_scores(df, year)['size_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52.3450093132096,\n",
       " 12.649110640673516,\n",
       " 17.88854381999832,\n",
       " 14.142135623730951,\n",
       " 19.493588689617926,\n",
       " 56.39148871948674,\n",
       " 17.320508075688775,\n",
       " 10.0,\n",
       " 31.937438845342626,\n",
       " 8.94427190999916,\n",
       " 12.649110640673516,\n",
       " 6.324555320336758,\n",
       " 25.690465157330262,\n",
       " 6.324555320336758,\n",
       " 4.47213595499958,\n",
       " 7.745966692414834,\n",
       " 4.47213595499958,\n",
       " 11.832159566199232,\n",
       " 14.832396974191326,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958,\n",
       " 4.47213595499958]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_entry_by_org_size_scores(df, year)['size_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[  0, 115,  78,  58,  40,  40,  35,  33,  32,  26],\n",
       "        [115,   0,  31,  50,  18,  22,   8,   4,  16,  17],\n",
       "        [ 78,  31,   0,  36,  19,   9,   6,  11,  11,  10],\n",
       "        [ 58,  50,  36,   0,  17,   4,   0,   8,  12,  11],\n",
       "        [ 40,  18,  19,  17,   0,   2,   2,   4,   8,  10],\n",
       "        [ 40,  22,   9,   4,   2,   0,   5,   0,   1,   3],\n",
       "        [ 35,   8,   6,   0,   2,   5,   0,   4,   2,   2],\n",
       "        [ 33,   4,  11,   8,   4,   0,   4,   0,   8,   1],\n",
       "        [ 32,  16,  11,  12,   8,   1,   2,   8,   0,   5],\n",
       "        [ 26,  17,  10,  11,  10,   3,   2,   1,   5,   0]]),\n",
       " 'label': ['eeg',\n",
       "  'electroencephalography',\n",
       "  'aivot',\n",
       "  'brain',\n",
       "  'meg',\n",
       "  'epilepsia',\n",
       "  'lapset',\n",
       "  'neuropsykologia',\n",
       "  'aivotutkimus',\n",
       "  'aivokuori']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_num_entry_by_org_size_scores(df, year)\n",
    "comat = get_cooccurrence_matrix(df)\n",
    "#comat.to_csv('comat.csv', sep='\\t', encoding='utf-8')\n",
    "#comat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg</th>\n",
       "      <th>electroencephalography</th>\n",
       "      <th>aivot</th>\n",
       "      <th>brain</th>\n",
       "      <th>meg</th>\n",
       "      <th>epilepsia</th>\n",
       "      <th>lapset</th>\n",
       "      <th>neuropsykologia</th>\n",
       "      <th>aivotutkimus</th>\n",
       "      <th>aivokuori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>78</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eeg  electroencephalography  aivot  brain  meg  epilepsia  lapset  \\\n",
       "0    0                     115     78     58   40         40      35   \n",
       "1  115                       0     31     50   18         22       8   \n",
       "2   78                      31      0     36   19          9       6   \n",
       "3   58                      50     36      0   17          4       0   \n",
       "4   40                      18     19     17    0          2       2   \n",
       "5   40                      22      9      4    2          0       5   \n",
       "6   35                       8      6      0    2          5       0   \n",
       "7   33                       4     11      8    4          0       4   \n",
       "8   32                      16     11     12    8          1       2   \n",
       "9   26                      17     10     11   10          3       2   \n",
       "\n",
       "   neuropsykologia  aivotutkimus  aivokuori  \n",
       "0               33            32         26  \n",
       "1                4            16         17  \n",
       "2               11            11         10  \n",
       "3                8            12         11  \n",
       "4                4             8         10  \n",
       "5                0             1          3  \n",
       "6                4             2          2  \n",
       "7                0             8          1  \n",
       "8                8             0          5  \n",
       "9                1             5          0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'institutions': ['Jyväskylän yliopisto',\n",
       "  'Turun ammattikorkeakoulu',\n",
       "  'Kansalliskirjasto',\n",
       "  'Turun yliopisto',\n",
       "  'Tampereen ammattikorkeakoulu',\n",
       "  'Helka-kirjastot',\n",
       "  'Oulun yliopisto',\n",
       "  'Savonia-ammattikorkeakoulu',\n",
       "  'Itä-Suomen yliopisto',\n",
       "  'Laurea-kirjasto',\n",
       "  'Oulun ammattikorkeakoulun kirjasto',\n",
       "  'Taideyliopisto',\n",
       "  'Aalto-yliopisto',\n",
       "  'Svenska handelshögskolan',\n",
       "  'Helsingin yliopistomuseo',\n",
       "  'Tampereen teknillinen yliopisto',\n",
       "  'Tritonia',\n",
       "  'Metropolian kirjaston kokoelmat',\n",
       "  'Åbo Akademis bibliotek',\n",
       "  'Arcadan kirjasto',\n",
       "  'Tampereen yliopisto',\n",
       "  'Lappeenrannan tiedekirjasto',\n",
       "  'Karelia-ammattikorkeakoulu',\n",
       "  'Varastokirjasto',\n",
       "  'Blanka-kirjastot',\n",
       "  'Centria-kirjasto',\n",
       "  'Eepos-kirjastot'],\n",
       " 'size_values': [52.3450093132096,\n",
       "  12.649110640673516,\n",
       "  17.88854381999832,\n",
       "  14.142135623730951,\n",
       "  19.493588689617926,\n",
       "  56.39148871948674,\n",
       "  17.320508075688775,\n",
       "  10.0,\n",
       "  31.937438845342626,\n",
       "  8.94427190999916,\n",
       "  12.649110640673516,\n",
       "  6.324555320336758,\n",
       "  25.690465157330262,\n",
       "  6.324555320336758,\n",
       "  4.47213595499958,\n",
       "  7.745966692414834,\n",
       "  4.47213595499958,\n",
       "  11.832159566199232,\n",
       "  14.832396974191326,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958,\n",
       "  4.47213595499958]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_entry_by_org_size_scores(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
